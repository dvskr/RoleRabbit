---
title: Resume AI System - Complete Architecture
version: 2.0
date: 2025-11-12
status: Production Ready
---

# Resume AI System - End-to-End Architecture

Complete technical documentation for RoleReady's AI-powered resume optimization system.

---

## 1. System Overview

**Core Features:**
- ðŸ“„ **Resume Parsing** - Extract structured data from PDF/DOCX
- ðŸŽ¯ **ATS Scoring** - Semantic + keyword-based matching (80/20 split)
- âœ¨ **Resume Tailoring** - AI-powered optimization (PARTIAL/FULL modes)

**Tech Stack:**
- Backend: Node.js, Prisma, PostgreSQL
- AI: OpenAI (embeddings + GPT-4o/4o-mini)
- Caching: Two-tier (in-memory + database)

---

## 2. Resume Parsing

### **2.1 Workflow**

```
User uploads PDF/DOCX
    â†“
File saved to storage (compute fileHash)
    â†“
User activates resume in slot
    â†“
Auto-parse if resume.data is empty
    â†“
Extract text â†’ AI structuring â†’ Save to DB
```

### **2.2 Smart Features**

**File Change Detection:**
- SHA-256 hash of file content
- Automatic re-parse on content change
- Cache hit for identical files

**Smart Truncation (Huge Resumes):**
- Trigger: >30K characters
- Priority: Skills â†’ Experience (top 5) â†’ Projects (top 3)
- Drops: Contact info, old jobs, excess bullets
- Result: 95% size reduction, valid JSON

**Caching:**
- Key: `fileHash`
- TTL: 24 hours
- Storage: Database (`resume_cache` table)

---

## 3. ATS Scoring

### **3.1 Architecture**

**Hybrid Approach (80% Semantic + 20% Keywords):**

```
Resume + Job Description
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Generate Embeddings (parallel)  â”‚
â”‚    - Resume embedding (1536-d)     â”‚
â”‚    - JD embedding (1536-d, cached) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Calculate Similarity             â”‚
â”‚    - Cosine similarity              â”‚
â”‚    - Semantic score (0-100)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Extract Skills (AI, parallel)   â”‚
â”‚    - JD skills (cached 24h)         â”‚
â”‚    - Resume skills (cached 24h)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Match Keywords                   â”‚
â”‚    - Matched skills                 â”‚
â”‚    - Missing skills (prioritized)   â”‚
â”‚    - Keyword match rate             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Score = (0.8 Ã— semantic) + (0.2 Ã— keywords)
```

### **3.2 AI Skill Extraction**

**Model:** `gpt-4o-mini`

**Prompt Strategy:**
- Extract: required_skills, preferred_skills, implicit_skills
- Filter: Generic words (200+ stop-word list)
- Context: Industry, seniority, role type

**Caching:**
- JD skills: 24h (by JD hash)
- Resume skills: 24h (by resume text hash)
- Single-flight: Prevents duplicate concurrent calls

### **3.3 Smart Truncation for Skill Extraction**

**For huge resumes (>30K chars):**
```javascript
Priority 1: Skills, Summary, Experience (top 5 jobs, 5 bullets each)
Priority 2: Projects (top 3)
Priority 3: Certifications, Education
Dropped: Contact info
```

**Result:** ~3K chars (95% reduction), all critical skills preserved

---

## 4. Resume Tailoring

### **4.1 Modes**

| Mode | Target Score | Model | Cost | Strategy |
|------|--------------|-------|------|----------|
| **PARTIAL** | 80+ | gpt-4o-mini | ~$0.002 | Natural keyword integration |
| **FULL** | 85+ | gpt-4o | ~$0.04 | Complete rewrite with metrics |

### **4.2 Workflow**

```
1. Validate inputs
    â†“
2. Apply smart truncation (if huge resume)
    â†“
3. Run ATS analysis (get current score + missing keywords)
    â†“
4. Calculate realistic ceiling
    â†“
5. Calculate target score (mode-aware: 80+ or 85+)
    â†“
6. Intelligent keyword selection (data-driven)
    â†“
7. Build AI prompt with performance targets
    â†“
8. AI tailoring (PARTIAL: gpt-4o-mini, FULL: gpt-4o)
    â†“
9. Parse JSON (with jsonrepair if needed)
    â†“
10. Verify with ATS-after
    â†“
11. Save tailored version + background embedding
```

### **4.3 Intelligent Keyword Limits**

**Data-Driven Calculation:**

```javascript
optimalLimit = Math.min(
  capacity,      // Resume space (10-35 keywords)
  need,          // Keywords for target (6-35 keywords)
  totalMissing   // Available keywords
)
```

**Capacity Factors:**
- Resume density (bullets per job)
- Experience count
- Project count

**Need Factors (PARTIAL â†’ 80+):**
- ATS 75-79: 6 keywords
- ATS 65-74: 12 keywords
- ATS 55-64: 18 keywords
- ATS 45-54: 22 keywords
- ATS <45: 25 keywords

**Need Factors (FULL â†’ 85+):**
- ATS 80-84: 8 keywords
- ATS 70-79: 15 keywords
- ATS 60-69: 25 keywords
- ATS 50-59: 30 keywords
- ATS <50: 35 keywords

### **4.4 Hybrid Keyword Approach**

**Give AI 1.5x keywords with recommendation:**

```javascript
recommendedLimit = 18  // Calculated optimal
flexibleLimit = 27     // 1.5 Ã— 18 = 27

// AI receives:
// - 27 keywords (â­ top 18 starred)
// - Recommendation: "~18 keywords optimal"
// - Guidance: "Use judgment, quality > quantity"
```

**Benefits:**
- AI sees 50% more keywords
- AI has clear guidance
- AI can adapt (15-25 keywords)
- Prevents stuffing (capped at 1.5x)

### **4.5 Prompt Structure**

```
ðŸŽ¯ PERFORMANCE TARGET:
- Current ATS: 62/100
- Target: 80/100
- Required Improvement: +18 points

ðŸ“‹ AVAILABLE KEYWORDS (27 total, prioritized):
1. React â­
2. Node.js â­
...
18. Agile â­
19. MongoDB
...
27. PowerShell

ðŸ’¡ KEYWORD INTEGRATION GUIDANCE:
- â­ Starred (top 18): HIGH PRIORITY
- Remaining: Use if natural
- Recommended: ~18 keywords
- Quality > Quantity

ðŸ“Š SCORING TARGETS:
- Technical Skills: 70/100 â†’ 85+
- Experience: 60/100 â†’ 90+
- Content Quality: 65/100 â†’ 85+

[MODE-SPECIFIC INSTRUCTIONS]

Base Resume: [smart truncated JSON]
Job Description: [truncated text]
```

---

## 5. Caching Strategy

### **5.1 Two-Tier Caching**

**Tier 1: In-Memory (node-cache)**
- Fast access (<1ms)
- Limited size (LRU eviction)
- Process-local

**Tier 2: Database**
- Persistent
- Shared across instances
- Content-hash based

### **5.2 Cache Keys**

| Data | Key | TTL | Storage |
|------|-----|-----|---------|
| Resume parse | `fileHash` | 24h | DB |
| JD embedding | SHA-256(JD) | 24h | DB |
| JD skills | SHA-256(JD) | 24h | DB |
| Resume skills | SHA-256(resume text) | 24h | DB |
| ATS score | `resumeId:jobHash` | 1h | Memory |

### **5.3 Single-Flight Mechanism**

**Prevents duplicate concurrent AI calls:**

```javascript
const inFlightRequests = new Map();

if (inFlightRequests.has(cacheKey)) {
  return inFlightRequests.get(cacheKey);  // Join existing request
}

const promise = makeAICall();
inFlightRequests.set(cacheKey, promise);
return promise;
```

---

## 6. Cost Analysis

### **6.1 Per-Operation Costs**

| Operation | First Run | Warm Cache | Notes |
|-----------|-----------|------------|-------|
| **Resume Parse** | $0.001-0.002 | $0 (cache hit) | One-time per resume |
| **ATS Check** | $0.001-0.002 | $0.0001-0.0004 | 4 API calls (2 embeddings + 2 skills) |
| **Tailor PARTIAL** | $0.002-0.003 | $0.002 | Includes ATS before/after |
| **Tailor FULL** | $0.035-0.045 | $0.035 | Uses gpt-4o |

### **6.2 Usage Patterns (4-page resume, long JD)**

| User Type | Volume/Day | Daily Cost | Monthly Cost |
|-----------|------------|------------|--------------|
| **Light** | 5 PARTIAL + 5 ATS | $0.02-0.03 | $0.60-0.90 |
| **Moderate** | 15 PARTIAL + 15 ATS | $0.05-0.08 | $1.50-2.40 |
| **Power** | 25 PARTIAL + 5 FULL + 30 ATS | $0.30-0.40 | $9-12 |

**Note:** Costs drop 70%+ after cache warm-up.

---

## 7. Performance

### **7.1 Latency**

| Operation | First Run | Warm Cache |
|-----------|-----------|------------|
| **Resume Parse** | 3-8s | 0.1s (cache hit) |
| **ATS Check** | 2-5s | 0.3-0.9s |
| **Tailor PARTIAL** | 15-60s | 10-40s |
| **Tailor FULL** | 25-75s | 20-55s |

### **7.2 Optimization Techniques**

**Parallel Execution:**
- Resume + JD embeddings (parallel)
- JD skills + Resume skills (parallel)
- ATS before + Job analysis (parallel)

**Smart Truncation:**
- Huge resumes: 95% size reduction
- Maintains all critical content
- Faster AI processing

**Caching:**
- 70%+ cost reduction after warm-up
- 80%+ latency reduction
- Content-hash based (automatic invalidation)

---

## 8. Data Flow

### **8.1 Complete User Journey**

```
1. User uploads resume.pdf
   â””â”€> File saved, fileHash computed

2. User activates resume in slot
   â””â”€> Auto-parse if empty
   â””â”€> Structured JSON saved to DB

3. User clicks "ATS Check"
   â”œâ”€> Generate embeddings (parallel)
   â”œâ”€> Extract skills (parallel, cached)
   â”œâ”€> Calculate similarity
   â”œâ”€> Match keywords
   â””â”€> Return score + missing keywords

4. User clicks "Tailor Resume" (PARTIAL)
   â”œâ”€> Run ATS analysis (reuse cache)
   â”œâ”€> Calculate target (80+)
   â”œâ”€> Intelligent keyword selection (18 recommended, 27 flexible)
   â”œâ”€> Build prompt with guidance
   â”œâ”€> AI tailoring (gpt-4o-mini)
   â”œâ”€> Verify with ATS-after
   â””â”€> Return tailored resume + diff

5. User reviews and applies changes
   â””â”€> Editor updated with tailored content
```

---

## 9. Key Algorithms

### **9.1 Realistic Ceiling**

```javascript
ceiling = 95  // Start optimistic

// Penalties:
if (experienceGap > 2 years) ceiling -= Math.min(20, gap Ã— 3)
if (skillMatchRate < 30%) ceiling -= 20
if (skillMatchRate < 50%) ceiling -= 10
if (format >= 85) ceiling = Math.min(92, ceiling)

ceiling = Math.max(70, ceiling)  // Never below 70
```

### **9.2 Target Score**

```javascript
// FULL mode: 85+ target
baseTarget = Math.max(85, currentScore + 25)
target = Math.min(ceiling, baseTarget)

// PARTIAL mode: 80+ target
baseTarget = Math.max(80, currentScore + 15)
target = Math.min(ceiling, baseTarget)
```

### **9.3 Keyword Prioritization**

```javascript
// Score each keyword by:
score = 
  (frequency in JD Ã— 3) +
  (isRequired ? 10 : 0) +
  (isPreferred ? 5 : 0) +
  (position bonus: earlier = higher)

// Sort by score, return top N
```

---

## 10. Error Handling

### **10.1 Graceful Degradation**

**AI Failures:**
- Skill extraction fails â†’ Pattern-based fallback
- JSON parsing fails â†’ jsonrepair library
- Embedding fails â†’ Return error, don't crash

**File Parsing:**
- PDF extraction fails â†’ OCR fallback (if available)
- DOCX parsing fails â†’ Return helpful error
- Huge files â†’ Smart truncation

### **10.2 Retry Strategy**

**Exponential Backoff:**
```javascript
maxRetries = 3
baseDelay = 1000ms
delay = baseDelay Ã— (2 ^ attempt)

// Retry on: 429 (rate limit), 500 (server error), timeout
```

---

## 11. Database Schema

### **11.1 Key Tables**

**`storage_files`:**
- `fileHash` - SHA-256 of content
- `storagePath` - S3/local path
- `contentType` - MIME type

**`base_resumes`:**
- `data` - Structured JSON
- `fileHash` - Link to storage file
- `storageFileId` - Foreign key
- `vector` - Embedding (1536-d)

**`resume_cache`:**
- `fileHash` - Cache key
- `data` - Parsed JSON
- `method` - 'ai' or 'pattern'
- `confidence` - 0-1

**`job_embeddings`:**
- `jobHash` - SHA-256 of JD
- `embedding` - 1536-d vector
- `metadata` - Skills, industry, etc.

---

## 12. Configuration

### **12.1 Environment Variables**

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Tailoring
ATS_TAILOR_MISSING_MAX=25  # Max keywords (overridden by intelligent calc)
ENABLE_PROMPT_COMPRESSION=true

# Caching
CACHE_TTL_EMBEDDINGS=86400  # 24h
CACHE_TTL_SKILLS=86400      # 24h
CACHE_TTL_ATS=3600          # 1h
```

### **12.2 Tunable Parameters**

**Smart Truncation:**
- Resume limit: 30,000 chars
- JD limit: 8,000 chars
- Priority sections: Skills, Experience, Projects

**Keyword Limits:**
- Flexible multiplier: 1.5x
- PARTIAL range: 6-25 keywords
- FULL range: 8-35 keywords

**Scoring:**
- Semantic weight: 80%
- Keyword weight: 20%

---

## 13. Monitoring & Metrics

### **13.1 Key Metrics**

**Performance:**
- ATS check latency (p50, p95, p99)
- Tailoring latency (p50, p95, p99)
- Cache hit rate (%)

**Quality:**
- ATS score improvement (before â†’ after)
- Keyword integration rate (%)
- User satisfaction (applied vs rejected)

**Cost:**
- OpenAI API spend ($/day)
- Cost per user ($/month)
- Cache efficiency (savings %)

### **13.2 Logging**

**Structured Logs:**
```javascript
logger.info('Hybrid keyword limit decision', {
  userId,
  mode,
  intelligentLimit,
  recommendedLimit,
  flexibleLimit,
  totalAvailable,
  strategy: 'Give AI 1.5x keywords'
});
```

---

## 14. Testing

### **14.1 Test Scripts**

```bash
# Test intelligent keyword limits
node test-intelligent-keyword-limits.js

# Test hybrid approach
node test-hybrid-keyword-approach.js

# Test smart truncation
node test-tailoring-huge-resume.js
```

### **14.2 Test Coverage**

**Scenarios:**
- Entry-level sparse resume
- Mid-level standard resume
- Senior dense resume
- Executive very dense resume
- Edge cases (few keywords, high score)

---

## 15. Future Enhancements

### **15.1 Short-Term (Optional)**

- Redis caching (distributed)
- Rerankers for top-K precision
- Domain-specific rules
- Role/industry calibration

### **15.2 Long-Term**

- ML model for keyword prediction
- A/B testing framework
- Real-time analytics dashboard
- Multi-language support

---

## 16. Quick Reference

### **16.1 File Locations**

```
apps/api/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ resumeParser.js              # Parsing logic
â”‚   â”œâ”€â”€ baseResumeService.js         # Resume management
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embeddingATSService.js   # ATS scoring
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ tailorService.js         # Tailoring logic
â”‚       â”œâ”€â”€ promptBuilder.js         # Prompt templates
â”‚       â”œâ”€â”€ aiSkillExtractor.js      # Skill extraction
â”‚       â””â”€â”€ intelligentKeywordLimits.js  # Keyword calculation
â””â”€â”€ utils/
    â””â”€â”€ realisticCeiling.js          # Target calculation
```

### **16.2 Key Functions**

```javascript
// Parsing
parseResumeByFileHash({ userId, fileHash, storageFileId })

// ATS
scoreResumeWithEmbeddings({ resumeData, jobDescription, includeDetails })

// Tailoring
tailorResume({ user, resumeId, jobDescription, mode, tone, length })

// Keywords
calculateOptimalKeywordLimit({ mode, atsScore, totalMissing, resumeData })
```

---

## 17. Summary

**System Highlights:**
- âœ… End-to-end AI-powered resume optimization
- âœ… Hybrid ATS scoring (80% semantic + 20% keywords)
- âœ… Intelligent keyword selection (data-driven)
- âœ… Smart truncation for huge resumes
- âœ… Two-tier caching (70%+ cost reduction)
- âœ… Production-ready with comprehensive testing

**Performance:**
- ðŸ“Š ATS check: 0.3-5s (depending on cache)
- ðŸ“Š Tailoring: 10-75s (depending on mode)
- ðŸ’° Cost: $0.02-0.40/day per active user

**Quality:**
- ðŸŽ¯ PARTIAL: 80+ ATS score target
- ðŸŽ¯ FULL: 85+ ATS score target
- ðŸŽ¯ Typical improvement: +10-45 points

---

**Last Updated:** 2025-11-12  
**Version:** 2.0  
**Status:** âœ… Production Ready

